{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import cv2\n",
    "import mmcv\n",
    "import mmengine\n",
    "import numpy as np\n",
    "import torch\n",
    "from mmdet.apis import inference_detector, init_detector\n",
    "\n",
    "from files import FileName\n",
    "from mmpose.evaluation.functional import nms\n",
    "from mmpose.utils import adapt_mmdet_pipeline\n",
    "from utils import calculate_iou, get_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"/home/ohwada/GSAT/MMPE/examples/img2.jpg\"\n",
    "video_path = \"/home/ohwada/GSAT/video/sample3.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/ohwada/GSAT/MMPE/models/rtmdet_m_8xb32-300e_coco.py\"\n",
    "config_path = \"/home/ohwada/GSAT/MMPE/models/rtmdet_m_8xb32-300e_coco_20220719_112220-229f527c.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_cat_id: int = 0\n",
    "bbox_thr: float = 0.3\n",
    "nms_thr: float = 0.3\n",
    "iou_thr: float = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loads checkpoint by local backend from path: /home/ohwada/GSAT/MMPE/models/rtmdet_m_8xb32-300e_coco_20220719_112220-229f527c.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: data_preprocessor.mean, data_preprocessor.std\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Load the model\n",
    "detector = init_detector(model_path, config_path, device=device)\n",
    "detector.cfg = adapt_mmdet_pipeline(detector.cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "_, img = cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_result = inference_detector(detector, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_instance = det_result.pred_instances.cpu().numpy()\n",
    "bboxes = np.concatenate((pred_instance.bboxes, pred_instance.scores[:, None]), axis=1)\n",
    "bboxes = bboxes[np.logical_and(pred_instance.labels == det_cat_id, pred_instance.scores > bbox_thr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(video_path)\n",
    "out = cv2.VideoWriter('output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 30, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "select_frame = 1\n",
    "conf_rank = 1\n",
    "\n",
    "frame_idx = 1\n",
    "tracked_box = None\n",
    "\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    det_result = inference_detector(detector, img)\n",
    "    \n",
    "    pred_instance = det_result.pred_instances.cpu().numpy()\n",
    "    bboxes = np.concatenate((pred_instance.bboxes, pred_instance.scores[:, None]), axis=1)\n",
    "    bboxes = bboxes[np.logical_and(pred_instance.labels == det_cat_id, pred_instance.scores > bbox_thr)]\n",
    "    \n",
    "    if frame_idx == select_frame:\n",
    "        sorted_bboxes = sorted(bboxes, key=lambda x: x[-1], reverse=True)\n",
    "        tracked_box = sorted_bboxes[conf_rank - 1][:4]\n",
    "        score = sorted_bboxes[conf_rank - 1][-1]\n",
    "    elif tracked_box is not None:\n",
    "        max_iou = 0\n",
    "        for bbox in bboxes:\n",
    "            box = bbox[:4]\n",
    "            score = bbox[-1]\n",
    "            iou = calculate_iou(tracked_box, box)\n",
    "            if iou > max_iou:\n",
    "                max_iou = iou\n",
    "                tracked_box = box\n",
    "        if max_iou < iou_thr:\n",
    "            tracked_box = None\n",
    "    \n",
    "    if tracked_box is not None:\n",
    "        x1, y1, x2, y2 = map(int, tracked_box)\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(img, f\"Conf: {score:.3f}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    \n",
    "    out.write(img)\n",
    "    \n",
    "    frame_idx += 1\n",
    "\n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
